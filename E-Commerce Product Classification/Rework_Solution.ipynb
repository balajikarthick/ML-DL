{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets recall the structure of our modified train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                            int64\n",
      "additionalAttributes         object\n",
      "label                         int64\n",
      "format                       object\n",
      "studio                       object\n",
      "language                     object\n",
      "actors                       object\n",
      "movie_genre                  object\n",
      "performer                    object\n",
      "upc                          object\n",
      "store_item_number_(dpci)     object\n",
      "tcin                        float64\n",
      "release_date                 object\n",
      "publisher                    object\n",
      "genre                        object\n",
      "number_of_pages              object\n",
      "size                         object\n",
      "color                        object\n",
      "asin                         object\n",
      "material                     object\n",
      "dtype: object \n",
      "\n",
      "(300000, 20) \n",
      "\n",
      "2    225376\n",
      "0     27924\n",
      "3     23376\n",
      "1     23324\n",
      "Name: label, dtype: int64 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balaji\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "m_train = pd.read_csv(\"mod_train.csv\", encoding = \"ISO-8859-1\", index_col=0)\n",
    "\n",
    "print(m_train.dtypes,\"\\n\")\n",
    "\n",
    "print(m_train.shape,\"\\n\")\n",
    "\n",
    "print(m_train.label.value_counts(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the accurancy of Mod_train csv and its confustion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = list(m_train.columns)\n",
    "columns.remove('id')\n",
    "columns.remove('label')\n",
    "columns.remove(\"additionalAttributes\")\n",
    "\n",
    "for x in columns:\n",
    "    m_train[x] = (m_train[x].notnull()).astype('int')\n",
    "\n",
    "#print(train.columns.ndarray)\n",
    "X = m_train.as_matrix(columns)\n",
    "y = m_train.label\n",
    "\n",
    "# dividing X, y into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# training a linear SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)\n",
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "\n",
    "# model accuracy for X_test \n",
    "accuracy = svm_model_linear.score(X_test, y_test)\n",
    "print (accuracy)\n",
    "\n",
    "cm = confusion_matrix(y_test, svm_predictions)\n",
    "\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the index mapping for the label is like below\n",
    "\n",
    "0 -> books, 1 -> music, 2 -> rest, 3 -> videos\n",
    "\n",
    "      0        1    2      3 \n",
    "\n",
    "0  [[ 5206     0  1731    33]\n",
    "1   [    1  4201  1610    61]\n",
    "2   [  114   222 56108     4]\n",
    "3   [   10    76  1290  4333]]\n",
    "\n",
    "From the confusion matrix we can infer that the predictions of books, videos , musics are proper but some of those are wrongly classified as rest.\n",
    "\n",
    "So we need to add some for usefull features that are capable of classifiying the features even more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per our previous approach we will first identify the top features in each category of label and identify which are those are usefull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " videos \n",
      "\n",
      "['format', 'studio', 'language', 'actors', 'movie_genre', 'upc', 'directors', 'rating', 'store_item_number_(dpci)', 'tcin', 'asin', 'dimensions', 'weight', 'author', 'genre', 'average_customer_review', 'origin', 'software_format', 'amazon_best_sellers_rank', 'region', 'country_of_origin', 'movie_studio', 'release_date', 'rated', 'run_time', 'duration', 'dvd_release_date', 'number_of_discs', 'edition', 'aspect_ratio', 'movie_category', 'original_languages', 'stars', 'mpaa_rating', 'subtitles', 'movie_mpaa_rating', 'brand', 'record_label', 'color', 'movie_picture_format', 'subtitle_language', 'condition', 'producers', 'writers', 'screen_format', 'director', 'manufacturer_part_number', 'dubbed', 'street_date', 'container_type', 'assembled_product_weight', 'extra_info', 'features', 'studio_name', 'audio_tracks', 'run_time_(in_minutes)', 'digital_video_formats', 'starring', 'number_of_tapes', 'model', 'vhs_release_date', 'voices', 'tv_rating', 'series_title', 'character', 'target_audience', '...', 'international_shipping', 'domestic_shipping', 'model_number', 'is_edited', '_ultraviolet', 'type', 'purchase_rights', 'genres', 'else_if_window.acrasinhover_', '}function_popoverready_jquery_{if_typeof_jquery_', '}_else_if_jquery.fn.acrpopover_{return', '}var_popoverconfig_', 'age_group', 'captions_and_subtitles', 'audio_description', 'occasion', 'sport', '_else_if_window.acrasinhover_', '_sensormatic', \"_}_amznjq.onready_'popover',_function_{_function_$_{_if_$.fn.acrpopover_return\", '_var_popoverconfig_', 'warranty', 'movie_subgenre', 'audio_track_codec', 'blu-ray_release_date', '_widescreen', '_checkpoint', 'supporting_actors', '_includes_digital_copy', 'primary_shelf_id', 'style', 'actual_color', 'gender']\n",
      "\n",
      " music \n",
      "\n",
      "['upc', 'release_date', 'label', 'record_label', 'performer', 'store_item_number_(dpci)', 'tcin', 'author', 'catalognumber', 'asin', 'software_format', 'amazon_best_sellers_rank', '1.', 'origin', 'pop_music_genre', 'average_customer_review', 'artist', 'number_of_discs', 'format', 'rank', 'pop_musical_style', 'pop_sub-genre', 'original_release_date', 'brand', 'street_date', '3.', '2.', '4.', '5.', '6.', '7.', '8.', '9.', '10.', '11.', '12.', 'genres', 'edition', 'duration', 'copyright', '13.', '14.', '15.', '16.', 'classical_music_genre', '17.', '18.', 'run_time', 'manufacturer_part_number', '19.', '20.', 'assembled_product_weight', '21.', '4', '22.', '3', '2', '23.', '5', '24.', 'composer', '1', 'classical_musical_period', 'total_length', '6', '25.', '26.', '7', '8', '...', '27.', '9', '28.', '29.', 'conductor', '30.', '10', 'orchestra', 'spars_code', '31.', '32.', 'parental_advisory', 'studio', '11', 'rated', '33.', 'note_on_boxed_sets', '34.', 'language', '35.', '12', 'dvd_release_date', 'region', '36.', 'features', '37.', 'actors', 'age_group', 'physical_media_format', '38.']\n",
      "\n",
      " rest \n",
      "\n",
      "['color', 'size', 'material', 'asin', 'upc', 'dimensions', 'country_of_origin', 'shipping_weight', 'model_number', 'care_and_cleaning', 'brand', 'manufacturer_part_number', 'item_model_number', 'sizing', 'manufacturer', 'type0', 'type1', 'type2', 'type3', 'item_weight', 'product_dimensions', 'type4', 'customer_reviews', 'closure_style', 'style', 'origin', 'type5', 'type', 'width', 'weight', 'pattern', 'type6', 'date_first_available', 'features', 'feature_0', 'tcin', 'warranty', 'feature_1', 'domestic_shipping', 'feature_2', 'model', 'type7', 'feature_3', 'gender', 'feature_4', 'average_customer_review', 'type8', 'international_shipping', 'height', 'pocket_style', 'feature_5', 'garment_length', 'shipping_information', 'type9', 'best_sellers_rank', 'condition', 'warranty_terms_-_parts', 'depth', 'feature_6', 'variant', 'finish', 'type10', 'feature_7', 'assembled_product_weight', 'shape', 'sleeve_style', 'color_category', 'amazon_best_sellers_rank', 'part_number', 'feature_8', 'weave_type', 'type11', 'rise', 'neckline_style', 'feature_9', 'brand_name', 'warranty_terms_-_labor', 'actual_color', 'type12', 'fit', 'product_features', 'care_instruction', 'feature_10', 'back_style', 'metal', 'publication_date', 'sheerness', 'hem_style', 'warranty_description', 'garment_construction', 'type13', 'feature_11', 'includes', 'assembly_details', 'knit_type', 'backing_material', 'store_item_number_(dpci)', 'rug_construction', 'number_of_pieces', 'package_dimensions']\n",
      "\n",
      " books \n",
      "\n",
      "['publisher', 'language', 'isbn-13', 'format', 'author', 'genre', 'isbn-10', 'number_of_pages', 'pages', 'product_dimensions', 'publication_date', 'isbn', 'book_format', 'publisher_date', 'audience', 'store_item_number_(dpci)', 'tcin', 'height', 'wdth', 'thickness', 'amazon_best_sellers_rank', 'unit_weight', 'origin', 'average_customer_review', 'authors', 'copyright_year', 'shipping_weight', 'publish_date', 'country_of_origin', 'sub-genre', 'series', 'edition', 'paperback', 'street_date', 'series_title', 'subtitle', 'age_range', 'series_name', 'edition_description', 'file_size', 'sold_by', 'dimensions', 'contributed_by', 'asin', 'hardcover', 'original_languages', 'walmart_no.', 'enhanced_typesetting', 'word_wise', 'print_length', 'sales_rank', 'x-ray', 'lending', 'edition_detail', 'text-to-speech', 'edition_number', 'subject', 'genre_detail', 'series_volume_number', 'upc', 'grade_level', 'simultaneous_device_usage', 'digital_video_formats', 'screen_reader', 'bn_id', 'volume_number', 'target_audience', 'lexile', 'lexile_measure', 'number_within_set', 'fiction/nonfiction', 'page_numbers_source_isbn', 'number_in_series', 'book_genre', 'manufacturer_part_number', 'format_books', 'brand', 'note', 'library_binding', 'book_subgenre', 'condition', 'mass_market_paperback', 'color', 'package_dimensions', 'illustrator', 'assembled_product_weight', 'program_type', 'version', 'audible.com_release_date', 'listening_length', 'isbn13', 'isbn10', 'spiral-bound', 'whispersync_for_voice', 'animal_type', 'gender', 'amazon_bestsellers_rank', 'contributor', 'age_group', 'features']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "train = pd.read_csv(\"bmv_training_set.csv\")\n",
    "set_label = set(train[\"label\"].values)\n",
    "for choices in set_label:\n",
    "    k = list()\n",
    "    print(\"\\n\",choices,\"\\n\")\n",
    "    text = train[\"additionalAttributes\"][train[\"label\"] == choices].values\n",
    "    res = \";\".join(text)\n",
    "    text = res.split(\";\")\n",
    "    text = [i.split('=')[0].replace(\":\",\"\").replace(\" \",\"_\").lower() for i in text] \n",
    "    for x , v in Counter(text).most_common(100):\n",
    "       k.append(x)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above chunck of data we can infer that \n",
    "\n",
    "1. \"Music\" label has some features which are numeric 1.,2.,3. extra\n",
    "2. \"Rest\" label has some features which are redendent like \"type0\", \"type1\", \"type2\", \"feature_1\", \"feature_2\", .. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets again dig into further more like what are the common words in the set of features of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " videos \n",
      "\n",
      "[('', 8), ('movie', 6), ('audio', 3), ('studio', 2), ('run', 2), ('number', 2), ('model', 2), ('format', 1), ('language', 1), ('actors', 1)]\n",
      "\n",
      " music \n",
      "\n",
      "[('pop', 3), ('classical', 2), ('upc', 1), ('release', 1), ('label', 1), ('record', 1), ('performer', 1), ('store', 1), ('tcin', 1), ('author', 1)]\n",
      "\n",
      " rest \n",
      "\n",
      "[('feature', 12), ('warranty', 4), ('color', 2), ('shipping', 2), ('model', 2), ('care', 2), ('brand', 2), ('manufacturer', 2), ('item', 2), ('product', 2)]\n",
      "\n",
      " books \n",
      "\n",
      "[('series', 4), ('edition', 4), ('number', 3), ('book', 3), ('publisher', 2), ('format', 2), ('genre', 2), ('amazon', 2), ('age', 2), ('lexile', 2)]\n"
     ]
    }
   ],
   "source": [
    "for choices in set_label:\n",
    "    k = list()\n",
    "    print(\"\\n\",choices,\"\\n\")\n",
    "    text = train[\"additionalAttributes\"][train[\"label\"] == choices].values\n",
    "    res = \";\".join(text)\n",
    "    text = res.split(\";\")\n",
    "    text = [i.split('=')[0].replace(\":\",\"\").replace(\" \",\"_\").lower() for i in text] \n",
    "    for x , v in Counter(text).most_common(100):\n",
    "       k.append(x)  \n",
    "    m = [i.split('_')[0] for i in k]\n",
    "    print(Counter(m).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the list of features in each category there are some features which has a starting word common. So out of 100 top features in each category which has more than 1 occurences in the feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " videos \n",
      "\n",
      "['movie', 'audio', 'studio', 'run', 'number', 'model']\n",
      "\n",
      " music \n",
      "\n",
      "['pop', 'classical']\n",
      "\n",
      " rest \n",
      "\n",
      "['feature', 'warranty', 'color', 'shipping', 'model', 'care', 'brand', 'manufacturer', 'item', 'product']\n",
      "\n",
      " books \n",
      "\n",
      "['series', 'edition', 'number', 'book', 'publisher', 'format', 'genre', 'amazon', 'age', 'lexile']\n"
     ]
    }
   ],
   "source": [
    "for choices in set_label:\n",
    "    k = list()\n",
    "    new_m= list()\n",
    "    print(\"\\n\",choices,\"\\n\")\n",
    "    text = train[\"additionalAttributes\"][train[\"label\"] == choices].values\n",
    "    res = \";\".join(text)\n",
    "    text = res.split(\";\")\n",
    "    text = [i.split('=')[0].replace(\":\",\"\").replace(\" \",\"_\").lower() for i in text] \n",
    "    for x , v in Counter(text).most_common(100):\n",
    "       k.append(x)  \n",
    "    m = [i.split('_')[0] for i in k]\n",
    "    for a, b in Counter(m).most_common(10):\n",
    "        if b > 1 and a != \"\":\n",
    "            new_m.append(a)\n",
    "    print(new_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we will combine the feature names that are starting with movie into a single feature \"movie\". For example if a videos category additionalAttributes has the following value\n",
    "\n",
    "movie genre=\"abcd\";movie name=\"abcd\";\n",
    "\n",
    "We will set the movie column for that row to be 1 to denote that the value contains a strong feature \"movie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will combine all those value into a single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie', 'audio', 'studio', 'run', 'number', 'model', 'pop', 'classical', 'feature', 'warranty', 'color', 'shipping', 'model', 'care', 'brand', 'manufacturer', 'item', 'product', 'series', 'edition', 'number', 'book', 'publisher', 'format', 'genre', 'amazon', 'age', 'lexile']\n"
     ]
    }
   ],
   "source": [
    "extract = list()\n",
    "features = list()\n",
    "for choices in set_label:\n",
    "    k = list()\n",
    "    text = train[\"additionalAttributes\"][train[\"label\"] == choices].values\n",
    "    res = \";\".join(text)\n",
    "    text = res.split(\";\")\n",
    "    text = [i.split('=')[0].replace(\":\",\"\").replace(\" \",\"_\").replace(\".\",\"\").lower() for i in text] \n",
    "    for x , v in Counter(text).most_common(100):\n",
    "       k.append(x)  \n",
    "    features.extend(k)\n",
    "    m = [i.split('_')[0] for i in k]\n",
    "    for a, b in Counter(m).most_common(10):\n",
    "        if b > 1 and a != \"\":\n",
    "            extract.append(a)\n",
    "print(extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step to identify the common features that appears in all the category. Though the feature appears to have more count if it presents in all the four category it won't be a valued feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['upc', 'store_item_number_(dpci)', 'tcin', 'asin', 'average_customer_review', 'origin', 'amazon_best_sellers_rank', 'brand', 'manufacturer_part_number', 'assembled_product_weight', 'features']\n"
     ]
    }
   ],
   "source": [
    "poor_features = list()\n",
    "for u , v in Counter(features).most_common(50):\n",
    "    if (v == 4):\n",
    "        poor_features.append(u)\n",
    "print(poor_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got the \"poor_features\", overall features in \"features\" and substring feature that appeared in top 10 as \"extract\". Next steps would be\n",
    "\n",
    "1. Removing duplicates from \"features\"\n",
    "2. Removing the feautres present in \"poor_features\" list\n",
    "3. Comibing the \"extract\" to the feautres and forming the \"final_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "['format', 'studio', 'language', 'actors', 'movie', 'directors', 'rating', 'store', 'dimensions', 'weight', 'author', 'genre', 'average', 'software', 'amazon', 'region', 'release', 'label', 'record', 'performer', 'catalognumber', '', 'pop', 'artist', 'number', 'rank', 'color', 'size', 'material', 'country', 'shipping', 'model', 'care', 'manufacturer', 'item', 'sizing', 'type', 'publisher', 'isbn', 'pages', 'product', 'publication', 'book', 'audience', 'height', 'wdth', 'thickness', 'audio', 'run', 'classical', 'feature', 'warranty', 'series', 'edition', 'age', 'lexile']\n"
     ]
    }
   ],
   "source": [
    "#Once again getting the features which has duplicates in it\n",
    "import re\n",
    "d_features = list() # Collection of features\n",
    "for choices in set_label:\n",
    "    k = list()\n",
    "    text = train[\"additionalAttributes\"][train[\"label\"] == choices].values\n",
    "    res = \";\".join(text)\n",
    "    text = res.split(\";\")\n",
    "    text = [i.split('=')[0].replace(\":\",\"\").replace(\" \",\"_\").replace(\".\",\"\").lower() for i in text] \n",
    "    for x , v in Counter(text).most_common(20):\n",
    "        x = re.sub('\\d+', '', x) #removing digits from features \n",
    "        x = x.strip(\":-,\")  #removing special characters\n",
    "        x = re.sub('_.*', '', x) #removing characters after _ to avoid duplicates from \"extract\"\n",
    "        k.append(x)  \n",
    "    d_features.extend(k)\n",
    "\n",
    "d_features.extend(extract) # Adding extracted data to the list of features\n",
    "\n",
    "n_features= list()\n",
    "feature_hash = Counter(d_features)\n",
    "for u , v in feature_hash.items():\n",
    "    n_features.append(u) # Removing Duplicates \n",
    "\n",
    "final_features = [x for x in n_features if x not in poor_features]\n",
    "print(len(final_features))#Final list of features after removing the poor_features \n",
    "print(final_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets add these features into our train data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying different approach to reduce the time taken using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 2)\n",
      "                                 additionalAttributes final_label  actors  \\\n",
      "id                                                                          \n",
      "0   Store Item Number (DPCI)=244-02-6685;Pop Music...       music     NaN   \n",
      "1   Package Dimensions=13.8 x 13 x 3.2 inches;Best...        rest     NaN   \n",
      "2               color=GREY;size=medium;Sizing:=Junior        rest     NaN   \n",
      "3   Product Dimensions=12 x 0 x 6 inches;ASIN=B00C...        rest     NaN   \n",
      "4                                              size=7        rest     NaN   \n",
      "5   Shipping Weight=5.8 ounces;ASIN=B00OVQRSCM;Ave...        rest     NaN   \n",
      "6   style=Necklace - 18 inches;Origin=USA;Product ...        rest     NaN   \n",
      "7   Compatibility=Car Radio;Feature_1=Material: AB...        rest     NaN   \n",
      "8   Gemstone Shape=Oval and Round;Gemstone Cut=Ova...        rest     NaN   \n",
      "9   Color Family=Brown;Features=strengthens nails,...        rest     NaN   \n",
      "10           Origin of Components=USA and/or Imported        rest     NaN   \n",
      "11  Model Number=48081624081;Country of Origin=Uni...        rest     NaN   \n",
      "12  Series=BT Telecommunications Series Book 4;ISB...       books     NaN   \n",
      "13  type6= Sharpen your combat skills, striking in...        rest     NaN   \n",
      "14  UPC=858311002646;Product Dimensions=2.5 x 2.5 ...        rest     NaN   \n",
      "15  Origin=Imported;TCIN=21508031;color=Macintosh ...        rest     NaN   \n",
      "16                                         size=42x84        rest     NaN   \n",
      "17  size=small;Material:=100%: Cotton,;Neckline St...        rest     NaN   \n",
      "18  Dimensions=See product dimension;颜色=彩色;长度=18英寸...        rest     NaN   \n",
      "19  Dimensions=12.5 inches deep x 7 inches wide x ...        rest     NaN   \n",
      "\n",
      "    age  amazon  artist  audience  audio  author  average   ...    sizing  \\\n",
      "id                                                          ...             \n",
      "0   NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "1   NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "2   NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "3   NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "4   NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "5   NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "6   NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "7   NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "8   NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "9   NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "10  NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "11  NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "12  NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "13  NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "14  NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "15  NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "16  NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "17  NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "18  NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "19  NaN     NaN     NaN       NaN    NaN     NaN      NaN   ...       NaN   \n",
      "\n",
      "    software  store  studio  thickness  track  type  warranty  wdth  weight  \n",
      "id                                                                           \n",
      "0        NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "1        NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "2        NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "3        NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "4        NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "5        NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "6        NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "7        NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "8        NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "9        NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "10       NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "11       NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "12       NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "13       NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "14       NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "15       NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "16       NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "17       NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "18       NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "19       NaN    NaN     NaN        NaN    NaN   NaN       NaN   NaN     NaN  \n",
      "\n",
      "[20 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "train = pd.read_csv(\"bmv_training_set.csv\", index_col=0)\n",
    "print(train.shape)\n",
    "final_features.appendadd_attr = train[\"additionalAttributes\"].values\n",
    "\n",
    "#new = list()\n",
    "text_n = list()\n",
    "for text in add_attr:\n",
    "    text = text.split(\";\")\n",
    "    text = [i.split('=')[0].replace(\":\",\"\").replace(\" \",\"_\").replace(\".\",\"\").lower().strip(\"?:;.'\") for i in text]\n",
    "    text = [re.sub('_.*', '', i) for i in text]\n",
    "    text = [re.sub('^\\d+','track',i) for i in text]\n",
    "    text = [re.sub('\\d','',i) for i in text]\n",
    "    text = list(set(text))\n",
    "    text = \" \".join(text)\n",
    "    text_n.append(text)\n",
    "\n",
    "print(text_n[16])\n",
    "dtm = vect.transform(text_n)\n",
    "print(dtm.toarray()[16])\n",
    "new = pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())\n",
    "train.update(new)\n",
    "print(train.head(20))\n",
    "\n",
    "#train.to_csv(\"modio_train.csv\")('track') #To denote the Tracks in music category\n",
    "vect.fit(final_features)\n",
    "features = vect.get_feature_names()\n",
    "train = train.rename(columns={'label': 'final_label'}) #Changing the target variable name as there is one feature \"label\" present\n",
    "train = train.reindex(columns = np.append( train.columns.values, features))\n",
    "print(train.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 additionalAttributes final_label  actors  \\\n",
      "id                                                                          \n",
      "0   Store Item Number (DPCI)=244-02-6685;Pop Music...       music     0.0   \n",
      "1   Package Dimensions=13.8 x 13 x 3.2 inches;Best...        rest     0.0   \n",
      "2               color=GREY;size=medium;Sizing:=Junior        rest     0.0   \n",
      "3   Product Dimensions=12 x 0 x 6 inches;ASIN=B00C...        rest     0.0   \n",
      "4                                              size=7        rest     0.0   \n",
      "\n",
      "    age  amazon  artist  audience  audio  author  average   ...    sizing  \\\n",
      "id                                                          ...             \n",
      "0   0.0     0.0     0.0       0.0    0.0     0.0      0.0   ...       0.0   \n",
      "1   0.0     0.0     0.0       0.0    0.0     0.0      0.0   ...       0.0   \n",
      "2   0.0     0.0     0.0       0.0    0.0     0.0      0.0   ...       1.0   \n",
      "3   0.0     0.0     0.0       0.0    0.0     0.0      0.0   ...       0.0   \n",
      "4   0.0     0.0     0.0       0.0    0.0     0.0      0.0   ...       0.0   \n",
      "\n",
      "    software  store  studio  thickness  track  type  warranty  wdth  weight  \n",
      "id                                                                           \n",
      "0        1.0    1.0     0.0        0.0    0.0   0.0       0.0   0.0     0.0  \n",
      "1        0.0    0.0     0.0        0.0    0.0   0.0       0.0   0.0     0.0  \n",
      "2        0.0    0.0     0.0        0.0    0.0   0.0       0.0   0.0     0.0  \n",
      "3        0.0    0.0     0.0        0.0    0.0   0.0       0.0   0.0     0.0  \n",
      "4        0.0    0.0     0.0        0.0    0.0   0.0       0.0   0.0     0.0  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "add_attr = train[\"additionalAttributes\"].values\n",
    "\n",
    "text_n = list()\n",
    "for text in add_attr:\n",
    "    text = text.split(\";\")\n",
    "    text = [i.split('=')[0].replace(\":\",\"\").replace(\" \",\"_\").replace(\".\",\"\").lower().strip(\"?:;.'\") for i in text]\n",
    "    text = [re.sub('_.*', '', i) for i in text]\n",
    "    text = [re.sub('^\\d+','track',i) for i in text]\n",
    "    text = [re.sub('\\d','',i) for i in text]\n",
    "    text = list(set(text))\n",
    "    text = \" \".join(text)\n",
    "    text_n.append(text)\n",
    "\n",
    "dtm = vect.transform(text_n)\n",
    "new = pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())\n",
    "train.update(new)\n",
    "print(train.head())\n",
    "\n",
    "train.to_csv(\"modified_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code took less than 3 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                               additionalAttributes  final_label  actors  \\\n",
      "0   0  Store Item Number (DPCI)=244-02-6685;Pop Music...            1       0   \n",
      "1   1  Package Dimensions=13.8 x 13 x 3.2 inches;Best...            2       0   \n",
      "2   2              color=GREY;size=medium;Sizing:=Junior            2       0   \n",
      "3   3  Product Dimensions=12 x 0 x 6 inches;ASIN=B00C...            2       0   \n",
      "4   4                                             size=7            2       0   \n",
      "\n",
      "   age  amazon  artist  audience  audio  author   ...    sizing  software  \\\n",
      "0    0       0       0         0      0       0   ...         0         1   \n",
      "1    0       0       0         0      0       0   ...         0         0   \n",
      "2    0       0       0         0      0       0   ...         1         0   \n",
      "3    0       0       0         0      0       0   ...         0         0   \n",
      "4    0       0       0         0      0       0   ...         0         0   \n",
      "\n",
      "   store  studio  thickness  track  type  warranty  wdth  weight  \n",
      "0      1       0          0      0     0         0     0       0  \n",
      "1      0       0          0      0     0         0     0       0  \n",
      "2      0       0          0      0     0         0     0       0  \n",
      "3      0       0          0      0     0         0     0       0  \n",
      "4      0       0          0      0     0         0     0       0  \n",
      "\n",
      "[5 rows x 59 columns]\n",
      "id                       int64\n",
      "additionalAttributes    object\n",
      "final_label               int8\n",
      "actors                   int32\n",
      "age                      int32\n",
      "amazon                   int32\n",
      "artist                   int32\n",
      "audience                 int32\n",
      "audio                    int32\n",
      "author                   int32\n",
      "average                  int32\n",
      "book                     int32\n",
      "care                     int32\n",
      "catalognumber            int32\n",
      "classical                int32\n",
      "color                    int32\n",
      "country                  int32\n",
      "dimensions               int32\n",
      "directors                int32\n",
      "edition                  int32\n",
      "feature                  int32\n",
      "format                   int32\n",
      "genre                    int32\n",
      "height                   int32\n",
      "isbn                     int32\n",
      "item                     int32\n",
      "label                    int32\n",
      "language                 int32\n",
      "lexile                   int32\n",
      "manufacturer             int32\n",
      "material                 int32\n",
      "model                    int32\n",
      "movie                    int32\n",
      "number                   int32\n",
      "pages                    int32\n",
      "performer                int32\n",
      "pop                      int32\n",
      "product                  int32\n",
      "publication              int32\n",
      "publisher                int32\n",
      "rank                     int32\n",
      "rating                   int32\n",
      "record                   int32\n",
      "region                   int32\n",
      "release                  int32\n",
      "run                      int32\n",
      "series                   int32\n",
      "shipping                 int32\n",
      "size                     int32\n",
      "sizing                   int32\n",
      "software                 int32\n",
      "store                    int32\n",
      "studio                   int32\n",
      "thickness                int32\n",
      "track                    int32\n",
      "type                     int32\n",
      "warranty                 int32\n",
      "wdth                     int32\n",
      "weight                   int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "train = pd.read_csv(\"bmv_training_set.csv\")\n",
    "m_train = pd.read_csv(\"modified_train.csv\", encoding = \"ISO-8859-1\")\n",
    "test = pd.read_csv(\"modified_test.csv\" , encoding = \"ISO-8859-1\", index_col=0)\n",
    "columns = list(m_train.columns)\n",
    "columns = columns[3:]\n",
    "\n",
    "m_train[\"final_label\"] = m_train[\"final_label\"].astype('category').cat.codes #converting the categories into int\n",
    "test[\"final_label\"] = np.nan\n",
    "\n",
    "slc = np.r_[columns]\n",
    "m_train[slc] = m_train[slc].astype(int)# converting all the dtypes to in\n",
    "\n",
    "print(m_train.head())\n",
    "\n",
    "print(m_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832066666667\n",
      "[[ 5783  1171    13     3]\n",
      " [   41  5809     1    22]\n",
      " [ 1912  5091 46453  2992]\n",
      " [   72  1261    16  4360]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#print(train.columns.ndarray)\n",
    "X = m_train.as_matrix(columns)\n",
    "y = m_train.final_label\n",
    "\n",
    "# dividing X, y into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    " \n",
    "# accuracy on X_test\n",
    "accuracy = gnb.score(X_test, y_test)\n",
    "print (accuracy)\n",
    "\n",
    "# creating a confusion matrix\n",
    "cm = confusion_matrix(y_test, gnb_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the accuracy improved. From the confusion matrix we can infer that the music category is wrongly classified \n",
    "\n",
    "0 -> books, 1 -> music, 2 -> rest, 3 -> videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9656\n",
      "[[ 5745  1168    56     1]\n",
      " [   26  5769    38    40]\n",
      " [   14     1 56428     5]\n",
      " [   11  1108   112  4478]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#print(m_train.columns.ndarray)\n",
    "X = m_train.as_matrix(columns)\n",
    "y = m_train.final_label\n",
    "\n",
    "# dividing X, y into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# training a linear SVM classifier\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)\n",
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "\n",
    "# model accuracy for X_test \n",
    "accuracy = svm_model_linear.score(X_test, y_test)\n",
    "print (accuracy)\n",
    "\n",
    "# creating a confusion matrix\n",
    "cm = confusion_matrix(y_test, svm_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is a good improvement in classifying the final_label. Need to fine tune the \"music\" label further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare submittion file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"bmv_test_set.csv\")\n",
    "vect.fit(features)\n",
    "features = vect.get_feature_names()\n",
    "test = test.rename(columns={'label': 'final_label'})\n",
    "test = test.reindex(columns = np.append( test.columns.values, features))\n",
    "print(test.head())\n",
    "\n",
    "add_attr = test[\"additionalAttributes\"].values\n",
    "\n",
    "text_n = list()\n",
    "for text in add_attr:\n",
    "    text = text.split(\";\")\n",
    "    text = [i.split('=')[0].replace(\":\",\"\").replace(\" \",\"_\").replace(\".\",\"\").lower().strip(\"?:;.'\") for i in text]\n",
    "    text = [re.sub('_.*', '', i) for i in text]\n",
    "    text = [re.sub('^\\d+','track',i) for i in text]\n",
    "    text = [re.sub('\\d','',i) for i in text]\n",
    "    text = list(set(text))\n",
    "    text = \" \".join(text)\n",
    "    text_n.append(text)\n",
    "\n",
    "dtm = vect.transform(text_n)\n",
    "new = pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())\n",
    "test.update(new)\n",
    "print(test.head())\n",
    "\n",
    "test.to_csv(\"modified_test.csv\")\n",
    "\n",
    "\n",
    "m_train = pd.read_csv(\"modified_train.csv\", encoding = \"ISO-8859-1\")\n",
    "m_test = pd.read_csv(\"modified_test.csv\" , encoding = \"ISO-8859-1\", index_col=0)\n",
    "columns = list(m_train.columns)\n",
    "columns = columns[3:]\n",
    "\n",
    "m_train[\"final_label\"] = m_train[\"final_label\"].astype('category').cat.codes #converting the categories into int\n",
    "m_test[\"final_label\"] = np.nan\n",
    "\n",
    "slc = np.r_[columns]\n",
    "m_train[slc] = m_train[slc].astype(int)# converting all the dtypes to in\n",
    "m_test[slc] = m_test[slc].astype(int)\n",
    "       \n",
    "       \n",
    "from sklearn.svm import SVC\n",
    "#print(train.columns.ndarray)\n",
    "X_train = m_train.as_matrix(columns)\n",
    "X_test = m_test.as_matrix(columns)\n",
    "\n",
    "y_train = m_train.final_label\n",
    "y_test = m_test.final_label\n",
    "\n",
    "# dividing X, y into train and test data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# training a linear SVM classifier\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)\n",
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    "\n",
    "m_test[\"final_label\"] = svm_predictions\n",
    "m_test.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                               additionalAttributes  label\n",
      "0   0  Movie Genre=Sports & Recreation;Store Item Num...      3\n",
      "1   1  author=Francis Ford Coppola featuring Marlon B...      0\n",
      "2   2  Performer=Phil Hamilton;Record Label=SELECT-O-...      1\n",
      "3   7                                       Color=Chrome      2\n",
      "4   9                          Format=Hardcover - $12.82      0\n",
      "(60000, 3)\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(\"submission.csv\", encoding = \"ISO-8859-1\", index_col=0)\n",
    "columns = list(sub.columns)\n",
    "columns = columns[2:58]\n",
    "sub.drop(columns, axis=1, inplace=True)\n",
    "sub.rename(columns={'final_label': 'label'}, inplace=True)\n",
    "print(sub.head())\n",
    "print(sub.shape)\n",
    "sub.to_csv(\"final_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
